# ğŸ¤– Robotics Vision

A smart interactive robot that detects and interacts with humans using AI and computer vision.  
Developed as a **graduation project** at Yanbu Industrial College, this robot integrates **HuskyLens**, **ESP32**, and **ChatGPT** to simulate human-like conversation and emotional eye expressions.

---

## ğŸ“Œ Overview
The project recognizes human presence and responds with facial expressions and voice-based interactions.  
It combines **AI conversation**, **face detection**, and **real-time eye animations**, creating a natural human-robot communication experience.

---

## ğŸ¯ Objectives
- Detect human presence using **HuskyLens**.  
- Enable AI conversation via **ChatGPT API**.  
- Display expressive animated eyes that react to user interaction.  
- Build a modular and scalable architecture for future development.

---

## âš™ï¸ Methodology & Design
- The robot uses **ESP32** microcontroller for data handling and communication.  
- **Python (Flask)** powers the animated eyes interface and AI logic.  
- **HuskyLens** provides real-time face detection and tracking.  
- **ChatGPT API** manages conversation and dialogue generation.  
- Data communication between **ESP32** and the **Python app** is handled via **UART**.

---

## ğŸ§  Tools & Technologies
| Category | Tools Used |
|-----------|-------------|
| Programming Languages | Python, C++ |
| AI & APIs | OpenAI ChatGPT API |
| Hardware | ESP32, HuskyLens AI Camera |
| Frameworks | Flask, PyGame |
| Development Tools | Visual Studio, Arduino IDE |

---

## ğŸ” Implementation Flow
1. **HuskyLens** detects human faces and sends a signal to **ESP32**.  
2. **ESP32** transmits detection status to the **Python GUI** through **UART**.  
3. The **Python app** triggers eye animations and initializes AI conversation using **ChatGPT**.  
4. Eye expressions dynamically change based on human interaction.  

---

## ğŸ§© Project Structure
Robotics-Vision/
â”œâ”€ esp32/
â”‚ â””â”€ huskylens_esp32.ino # Arduino sketch (ESP32)
â”œâ”€ server/
â”‚ â”œâ”€ app.py # Flask API server
â”‚ â”œâ”€ openai_handler.py # Handles ChatGPT API requests
â”‚ â”œâ”€ db.py # SQLite helper
â”‚ â””â”€ requirements.txt
â”œâ”€ ui/
â”‚ â”œâ”€ eye_display.py # Animated eyes display (PyGame)
â”‚ â””â”€ assets/ # Images, icons, or GIFs for eyes
â”œâ”€ docs/
â”‚ â”œâ”€ wiring_diagram.png
â”‚ â””â”€ demo.gif # Short demo preview
â”œâ”€ .env.example
â”œâ”€ .gitignore
â”œâ”€ README.md
â””â”€ LICENSEØ¯

---

## ğŸ“ˆ Results
- The robot successfully detects human presence.  
- Responds with voice and expressive eye animations.  
- Works efficiently in real time with smooth synchronization.  

---

## ğŸš€ Future Improvements
- Add voice recognition input.  
- Integrate emotional expressions and natural movement.  
- Support mobile or web-based remote control.  
- Use MQTT or socket networking for multi-device communication.  
- Deploy on **Raspberry Pi** for full embedded performance.

---

 ğŸ§‘â€ğŸ’» Developer
**Amal Mohammed Albarakati**  
Yanbu Industrial College â€“ Computer Science (Software Engineering Path)  
Graduation Project supervised by **Basma Aldahlan**

---

## ğŸª„ Installation

# Clone the repository
git clone https://github.com/<your-username>/Robotics-Vision.git
cd Robotics-Vision

# Install dependencies
pip install -r requirements.txt

# Run the application
python app.py
ğŸ§  Demo
<img width="894" height="269" alt="Ù„Ù‚Ø·Ø© Ø´Ø§Ø´Ø© 2025-10-15 213601" src="https://github.com/user-attachments/assets/189f3e6d-b292-4abc-8d35-55071e481071" />
<img width="688" height="310" alt="Ù„Ù‚Ø·Ø© Ø´Ø§Ø´Ø© 2025-10-15 213539" src="https://github.com/user-attachments/assets/46f7a609-325d-4f4b-acd7-ea8b85700069" />
<img width="947" height="848" alt="image" src="https://github.com/user-attachments/assets/56b6e271-00f9-4e3e-8958-ddaa9990d049" />

ğŸ“œ License
This project is for educational and research purposes.
Â© 2025 Amal Mohammed Albarakati. All rights reserved.


